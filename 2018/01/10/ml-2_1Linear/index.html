<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.ico?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="机器学习,线性模型," />





  <link rel="alternate" href="/atom.xml" title="月六象棋" type="application/atom+xml" />






<meta name="description" content="机器学习的相关知识系统的总结一遍，以便复习和加深印象。">
<meta name="keywords" content="机器学习,线性模型">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习总结（二）：线性模型">
<meta property="og:url" content="http://yoursite.com/2018/01/10/ml-2_1Linear/index.html">
<meta property="og:site_name" content="月六象棋">
<meta property="og:description" content="机器学习的相关知识系统的总结一遍，以便复习和加深印象。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://yoursite.com/2018/01/10/ml-2_1Linear/img/md-2/1.jpg">
<meta property="og:updated_time" content="2018-08-18T06:53:05.152Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习总结（二）：线性模型">
<meta name="twitter:description" content="机器学习的相关知识系统的总结一遍，以便复习和加深印象。">
<meta name="twitter:image" content="http://yoursite.com/2018/01/10/ml-2_1Linear/img/md-2/1.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/01/10/ml-2_1Linear/"/>





  <title>机器学习总结（二）：线性模型 | 月六象棋</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">月六象棋</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">机器学习和人工智能</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br />
            
            站点地图
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/10/ml-2_1Linear/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HF">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="月六象棋">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">机器学习总结（二）：线性模型</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-10T00:00:00+08:00">
                2018-01-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><img src="./img/md-2/1.jpg" style="zoom:80%"></p>
<p>　　<strong>机器学习的相关知识系统的总结一遍，以便复习和加深印象。</strong> <a id="more"></a> # 机器学习总结（二）：线性模型</p>
<h2 id="基本形式">1.基本形式</h2>
<p>　　对于给定<span class="math display">\[d\]</span>个属性描述的示例<span class="math display">\[x\]</span> =（<span class="math display">\[x_1\]</span>，<span class="math display">\[x_2\]</span>，...，<span class="math display">\[x_d\]</span>）,通过属性的线性组合来进行预测。一般的写法如下：</p>
<p>　　<span class="math display">\[f\left( x\right) =w^{T}x+b\]</span></p>
<p>　　线性模型具有很好的<strong>解释性</strong>（understandability，comprehensibility），参数<span class="math display">\[w\]</span>代表每个属性在回归过程中的重要程度。</p>
<h2 id="线性回归">2.线性回归</h2>
<p>　　线性回归（linear regression）试图试图学习到一个线性模型以尽可能准确的预测实值输出标记。</p>
<p>　　对于简单的单变量（只有一个属性<span class="math display">\[x\]</span>）问题，则线性回归试图学得：<span class="math display">\[f\left( x_{i}\right) =wx_{i}+b\]</span>，使得<span class="math display">\[f\left( x_{i}\right) \simeq y\left( i\right)\]</span>。可以使用”最小二乘法“（试图找到一条直线，使得所有样本到直线上的欧氏距离之和最小），求导得到<span class="math display">\[w\]</span>,<span class="math display">\[b\]</span>的值。（具体步骤见西瓜书54页）</p>
<p>　　对于多变量（有<span class="math display">\[d\]</span>个属性）问题，线性回归试图学得：<span class="math display">\[f\left( x_{i}\right) =w^{T}x_{i}+b\]</span>，使得<span class="math display">\[f\left( x_{i}\right) \simeq y\left( i\right)\]</span>。可以使用</p>
<p>　　“最小二乘法”（把<span class="math display">\[w\]</span>,<span class="math display">\[b\]</span>吸入向量模式<span class="math display">\[\widehat {w}{\ast }\]</span>，使用正规方程求得 <span class="math display">\[\widehat {w}{\ast }=\left( X^{T}X\right) ^{-1}X^{T}y\]</span> ）求得相应的<span class="math display">\[w\]</span>,<span class="math display">\[b\]</span>的值。（具体步骤见西瓜书及吴恩达机器学习课程）</p>
<h2 id="对数几率回归">3.对数几率回归</h2>
<p>　　找一个单调可微函数将分类任务的真实标记<span class="math display">\[y\]</span>与线性回归模型的预测值联系起来。</p>
<p>　　对于二分类任务，输出标记为<span class="math display">\[y\in \left\{ 0,1\right\}\]</span>，而线性回归的预测结果<span class="math display">\[h\left( x\right) =w^{T}x+b\]</span>，很明显是一个连续值，所以需要将其转换<strong>0/1</strong>值。所以要用到<strong>单位阶越函数</strong>：</p>
<p><span class="math display">\[y=\begin{cases}0,h\left( x\right) &lt;0;\\ 0\cdot 5,h\left( X\right) =0;\\ 1,h\left( x\right) &gt;0\end{cases}\]</span></p>
<p>即，若预测值大于0，就判为正例；若预测值小于0，就判为负例；临界值处，任意判别。 阶跃函数不可导，不连续，而<strong>广义线性回归模型</strong>（<span class="math display">\[y=g^{-1}\left( w^{T}x+b\right)\]</span>）必须是一个可微的函数，需要找一个连续函数代替阶跃函数。 常用<strong>对数几率函数</strong>（logistic function）来进行替代：</p>
<p><span class="math display">\[y=\dfrac {1}{1+e^{-z}}\]</span></p>
<p>画出图形会看到它形似S，所以也是一种sigmoid函数。把对数几率函数代入到广义线性回归的公式中：</p>
<p><span class="math display">\[y=\dfrac {1}{1+e^{-\left( w^{T}x+b\right) }}\]</span></p>
<p>做一些化简，可以得到：</p>
<p><span class="math display">\[\ln \left( \dfrac {y}{1-y}\right) =w^{T}x+b\]</span></p>
<p>其中，<span class="math display">\[y\]</span>是正例的可能性，<span class="math display">\[（1-y）\]</span>是负例的可能性。 那么，这个<span class="math display">\[\ln \left( \dfrac {y}{1-y}\right) \]</span>其实就是“对数几率”，可以看出，对数几率回归实质上就是使用线性回归模型<span class="math display">\[w^{T}x+b\]</span>来逼近这个对数几率<span class="math display">\[\ln \left( \dfrac {y}{1-y}\right) \]</span>。</p>
<p>　　如何求解出这个模型中的未知参数<span class="math display">\[w\]</span>和<span class="math display">\[b\]</span>呢？只考虑二分类的情况下，将y换成后验概率<span class="math display">\[P( y= 1|x)\]</span>来表示，同理1-y可以换成<span class="math display">\[P( y= 0|x)\]</span>。 则有：</p>
<p><span class="math display">\[\begin{cases}\ln \left(  \dfrac {P( y= 1|x)}{P( y= 0|x)}\right) =w^{T}x+b\\ P( y= 1|x) +P( y= 0|x) = 1\end{cases}\]</span></p>
<p>解得：</p>
<p><span class="math display">\[\begin{cases}\ P( y= 1|x) = \dfrac {e^{w^{T}x+b}}{1+e^{w^{T}x+b}}\\ P( y= 0|x) = \dfrac 1{1+e^{w^{T}x+b}}\end{cases}\]</span></p>
<p>通过极大似然法来估计<span class="math display">\[w\]</span>和<span class="math display">\[b\]</span>：</p>
<p><span class="math display">\[L\left( w,b\right) =\sum ^{n}_{i=1}\ln \left( P\left( y_{i}|x_{i};w,b\right) \right)\]</span></p>
<p>为表述方便，使用一个新矩阵<span class="math display">\[β\]</span>来表示<span class="math display">\[w\]</span>和<span class="math display">\[b\]</span>，令<span class="math display">\[\beta =\left( w;b\right)\]</span>。同时也要给<span class="math display">\[x\]</span>矩阵补上一列<span class="math display">\[1\]</span>，令<span class="math display">\[\widehat {x}=\left( x;1\right)\]</span>。那么，<span class="math display">\[w^{T}x+b=\beta ^{T}\widehat {x}\]</span>。由于是二分类，即只有<span class="math display">\[y=0\]</span>和<span class="math display">\[y=1\]</span>的情况，那么可以将似然项重写为<span class="math display">\[y=0\]</span>和<span class="math display">\[y=1\]</span>的情况相加：</p>
<p><span class="math display">\[P\left( y_{i}|x_{i};w,b\right) =y_{i}P_{1}\left( \widehat {x}_{i};\beta \right) +\left( 1-y_{i}\right) P_{0}\left( \widehat {x}_{i};\beta \right) \]</span></p>
<p>将上式代入到前面极大似然的公式中,并联立<span class="math display">\[\begin{cases}\ P( y= 1|x) = \dfrac {e^{w^{T}x+b}}{1+e^{w^{T}x+b}}\\ P( y= 0|x) = \dfrac 1{1+e^{w^{T}x+b}}\end{cases}\]</span>，得到最后的结果：</p>
<p><span class="math display">\[L\left( \beta\right) =\sum ^{m}_{i=1}\left( y_{i}\beta ^{T}\widehat {x}_{i}-\ln \left( 1+e^{\beta ^{T}\widehat {x}_{i}}\right) \right)\]</span></p>
<p>最大化上式等价于最小化：</p>
<p><span class="math display">\[L\left( \beta\right) =\sum ^{m}_{i=1}\left( -y_{i}\beta ^{T}\widehat {x}_{i}+\ln \left( 1+e^{\beta ^{T}\widehat {x}_{i}}\right) \right)\]</span></p>
<p>也就是求得<span class="math display">\[\beta ^{\ast }=\arg \min _{\beta }L\left( \beta \right)\]</span>，即求得<span class="math display">\[\beta ^{\ast }\]</span>的值使得函数<span class="math display">\[L\left( \beta \right)\]</span>最小。最后可以通过凸优化中的梯度下降法、牛顿法等方法来求出<span class="math display">\[L\left( \beta \right)\]</span>函数的最优解<span class="math display">\[\beta ^{\ast }\]</span>。</p>
<h2 id="线性判别分析lda">4.线性判别分析（<span class="math inline">\(LDA\)</span>）</h2>
<p>　　思想：给定训练样例集，设法将样例投影到一条直线上，使同类的投影点尽可能接近、异类样例的投影点尽肯能远离；在对新样本进行分类时，将其投影到同样的这条直线上，根据投影点的距离来确定新样本的类别。</p>
<h3 id="符号">符号</h3>
<ul>
<li><span class="math display">\[x\]</span>：表示训练样本（列向量）</li>
<li><span class="math display">\[x^{j}_{i}\]</span>：表示第<span class="math display">\[i\]</span>类中的第<span class="math display">\[j\]</span>个样本</li>
<li><span class="math display">\[C\]</span>：表示有<span class="math display">\[C\]</span>类样本</li>
<li><span class="math display">\[\mu _{i}\]</span>：表示第<span class="math display">\[i\]</span>类训练样本的均值 （<span class="math display">\[i\]</span>=<span class="math display">\[1\]</span>,<span class="math display">\[2\]</span>,…,<span class="math display">\[C\]</span>）</li>
<li><span class="math display">\[M_{i}\]</span>：表示第<span class="math display">\[i\]</span>类训练样本的数目</li>
<li><span class="math display">\[M\]</span>：示训练样本的总数目 <span class="math display">\[M = \sum^{C}_{i = 0}M_{i}\]</span></li>
<li><span class="math display">\[\mu\]</span>：是所有样本的均值向量</li>
<li><span class="math display">\[D_{i}\]</span>：表示第<span class="math display">\[i\]</span>类样本集合</li>
<li><span class="math display">\[S_{w}\]</span>：表示类内散度矩阵（<strong>within-class scatter matrix</strong>）</li>
<li><span class="math display">\[S_{b}\]</span>：表示类间散度矩阵（<strong>between-class scatter matrix</strong>）</li>
</ul>
<h3 id="优化目标">优化目标</h3>
<p>　　将数据点投影到直线上（可能是多条直线），直线的函数解析式又称为线性函数。通常直线的表达式为:</p>
<p><span class="math display">\[y=w^{T}x\]</span></p>
<p><span class="math display">\[x\]</span>就是样本向量（列向量），如果投影到一条直线上<span class="math display">\[w\]</span>就是一个特征向量（列向量形式）或者多个特征向量构成的矩阵。<span class="math display">\[y\]</span>为投影后的样本点（列向量）。将数据投影到直线<span class="math display">\[w\]</span>上，则两类样本的中心在直线上的投影分别为<span class="math display">\[w^{T}u_{0}\]</span>和<span class="math display">\[w^{T}u_{1}\]</span>，若将所有的样本点都都投影到直线上，则两类样本的协方差分别为<span class="math display">\[w^{T}\Sigma _{0}w\]</span>和<span class="math display">\[w^{T}\Sigma _{1}w\]</span> 。</p>
<p>　　欲使同类样例的投影点尽可能接近，可以让同类样本点的协方差矩阵尽可能小，即<span class="math display">\[w^{T}\Sigma _{0}w + w^{T}\Sigma _{1}w\]</span> 尽可能小; 而欲使异类样例的投影点尽可能远离，可以让类中心之间的距离尽可能大，即<span class="math display">\[||w^{T}u_{0}-w^{T}u_{1}||^2 _{2}\]</span> 尽可能大。同时考虑二者，则可得到欲最大化的目标：</p>
<p><span class="math display">\[J=\dfrac {||w^{T}u_{0}-w^{T}u_{1}||^2 _{2}}{w^{T}\left( \Sigma _{0}+\Sigma _{1}\right) w} = \dfrac {w^{T}(u_{0}-u_{1})(u_{0}-u_{1})^Tw}{w^{T}\left( \Sigma _{0}+\Sigma _{1}\right) w}\]</span></p>
<h3 id="类内散度矩阵">类内散度矩阵</h3>
<p>　　对于两类问题而言：</p>
<p><span class="math display">\[S_{w}=\Sigma _{0}+\Sigma _{1}=\sum _{x\in D_{0}}\left( x-\mu _{0}\right) \left( x-\mu _{0}\right) ^{T} + \sum _{x\in D_{1}}\left( x-\mu _{1}\right) \left( x-\mu _{1}\right) ^{T}\]</span></p>
<p>　　对于多类问题而言：</p>
<p><span class="math display">\[S_{w}=\sum ^{C}_{i=i}\sum ^{M_{i}}_{j=1}\left( x^{j}_{i}-\mu _{i}\right) \left( x^{j}_{i}-\mu _{i}\right) ^{T}\]</span></p>
<p>其中：</p>
<p><span class="math display">\[\sum ^{M_{i}}_{j=1}\left( x^{j}_{i}-\mu _{i}\right) \left( x^{j}_{i}-\mu _{i}\right) ^{T}\]</span></p>
<p>表示第<span class="math display">\[i\]</span>类样本的协方差矩阵。所以<span class="math display">\[S_w\]</span>就是表示<span class="math display">\[C\]</span>类样本协方差矩阵之和。</p>
<h3 id="类间散度矩阵">类间散度矩阵</h3>
<p>　　对于两类问题而言：</p>
<p><span class="math display">\[S_{b}=\left( \mu _{0}-\mu_{1}\right)\left( \mu _{0}-\mu_{1}\right)  ^{T}\]</span></p>
<p>　　对于多类问题而言：</p>
<p><span class="math display">\[S_{b}=\sum ^{C}_{i=i}\left( \mu _{i}-\mu\right)\left( \mu _{i}-\mu\right)  ^{T}\]</span></p>
<p><span class="math display">\[S_b\]</span>表示各个类样本均值的协方差矩阵。</p>
<h3 id="优化">优化</h3>
<p>　　定义过类内散度矩阵和类间散度矩阵后，我们可以将上述的优化目标重新写为：</p>
<p><span class="math display">\[J= \dfrac {w^{T}S_{b}w}{w^{T}S_{w}w}\]</span></p>
<p>这就是<span class="math display">\[LDA\]</span>欲最大化的目标，即<span class="math display">\[S_b\]</span>与<span class="math display">\[S_w\]</span>的广义瑞利商。如何确定<span class="math display">\[w\]</span>呢？注意到上式的分子和分母都是关于<span class="math display">\[w\]</span>的二次项，因此上式的解与<span class="math display">\[w\]</span>的长度无关,只与其方向有关.不失一般性，令<span class="math display">\[w^{T}S_{w}w=1\]</span>,则上式等价于：</p>
<p><span class="math display">\[min_w  -w^{T}S_{b}w\]</span></p>
<p><span class="math display">\[st. w^{T}S_{w}w=1\]</span></p>
<p>使用拉格朗日乘子法，可得：</p>
<p><span class="math display">\[c\left( w\right) =w^{T}S_{b}w-\lambda \left( w^{T}S_{w}w-1\right)\]</span></p>
<p><span class="math display">\[\dfrac {dc}{dw}=2S_{b}w-2\lambda S_{w}w=0\]</span></p>
<p><span class="math display">\[S_{b}w = \lambda S_{w} w\]</span></p>
<p><span class="math display">\[S^{-1}_{w}S_{b}w=\lambda w\]</span></p>
<p><span class="math display">\[w\]</span>的闭式解则是<span class="math display">\[S^{-1}_{w}S_{b}\]</span>的<span class="math display">\[N-1\]</span>个最大广义特征值所对应的特征向量组成的矩阵。若将<span class="math display">\[w\]</span>视为一个投影矩阵，则多分类<span class="math display">\[LDA\]</span>将样本投影到<span class="math display">\[N-1\]</span>维空间，从而减小样本点的维数，且投影过程中使用的类别信息，因此<span class="math display">\[LDA\]</span>被视为一种经典的监督降维方法。</p>
<h2 id="多分类学习">5.多分类学习</h2>
<p>　　多分类学习的基本思路是“拆解法”，即将多分类任务拆为若干个二分类任务求解。具体来说，先对问题进行拆分，然后为拆除的每个二分类任务训练一个分类器；在测试时，对这些分类器的预测结果进行集成以获得最终的多分类结果。关键问题：<strong>拆分</strong>和<strong>集成</strong>。</p>
<p>　　最经典的拆分策略有三种：“一对一(OvO)”、“一对其余(OvR)”、”多对多(MvM)”。</p>
<ul>
<li>OvO:将<span class="math display">\[N\]</span>个类别两两匹配，从而产生<span class="math display">\[N(N−1)/2\]</span>个二分类器。将新样本提交给所有的分类器，得到了<span class="math display">\[N(N−1)/2\]</span>个结果，最终结果通过投票产生。N比较大的时候，代价还是很高。</li>
<li>OvR:每次将一个类作为样例的正例，其他所有均作为反例，得到<span class="math display">\[N\]</span>个分类器。提交新的样本同时也得到<span class="math display">\[N\]</span>个结果，最终结果通过投票产生。</li>
<li>MvM:每次将若干个类作为正例、若干个类作为反例。显然OvO、OvR都是其特例。MvM的正、反类设计必须有特殊的设计，常用的一种技术：”纠错输出码”，简称ECOC。 ECOC是将编码的思想引入类别的划分，并可能在解码过程中具有容错性。ECOC工作过程主要分为两步：</li>
<li>编码：对N个类做M次划分，每次划分将一部分作为正类，一部分划分反类，从而形成一个二分类训练集。一共产生M个训练集，训练出M个分类器。</li>
<li>解码：M个分类器分别对测试样本进行预测，这些预测标记组成一个编码。将这个预测编码与每个类各自的编码进行比较，返回其中距离最小的类别作为最终结果。</li>
<li>对同一个学习任务来说，ECOC编码越长，纠错能力越强。然而编码越长所需要的训练的分类器越多，计算存储开销都会增大；另一方面对于有限类别码长超过一定范围就没有意义了。对于同等长度的编码，理论上来说，任务两个类别之间的编码距离越远，则纠错能力越强。</li>
</ul>
<h2 id="类别不平衡问题">6.类别不平衡问题</h2>
<p>　　类别不平衡就是指分类任务中不同类别的训练样例数目差别很大的情况。</p>
<p>　　从线性分类器角度考虑，利用<span class="math display">\[y=w^Tx+b\]</span>对新样本<span class="math display">\[x\]</span>做分类，若<span class="math display">\[y&gt;0.5\]</span>即为正例，否则为反例。几率<span class="math display">\[ \dfrac {y}{1-y}\]</span>正反映了正例可能性和反例可能性的比值，那么分类器的决策规则为:<span class="math display">\[ \dfrac {y}{1-y} &gt; 1\]</span>则预测为正例。</p>
<p>　　然而，当训练集正、反例数量不同时，令<span class="math display">\[m^+\]</span>表示正例数目，<span class="math display">\[m^−\]</span>表示反例数目，则观测几率是<span class="math display">\[ \dfrac {m^+}{m^-}\]</span>，由于训练是对真实样本的无偏采样，因此观测几率就代表了真实几率，于是只要分类器的预测几率高于观测记录就应判为正例，即<span class="math display">\[ \dfrac {y}{1-y} &gt; \dfrac {m^+}{m^-}\]</span>则预测为正例。这时候就可以令<span class="math display">\[ \dfrac {y^`}{1-y^`} =\dfrac {y}{1-y}\times\dfrac {m^+}{m^-}\]</span>，这就是类别不平衡的一个基本策略—“再缩放”。</p>
<p>　　在缩放思想虽简单，但实际操作并不平凡，主要因为“训练集是真实样本总体的无偏采样”这个假设往往不成立，也就是说，未必能有效地基于训练集观测几率来推断出真实几率。在这种情况下，现有技术大体有三种做法（假定正类样例少，反类样例多）：第一类是直接对训练集例的反类样例进行“欠采样”，即除去一些反例样本，使正反接近。第二类是对训练集中的正类样本进行“过采样”，即增加一些正例样本，使正反接近。第三类是直接基于原始数据训练集进行学习，但在应训练好的分类器进行预测时，将再缩放策略嵌入其决策过程中，称为“阀值移动”。</p>
<p>　　欠采样的时间开销通常远小于过采样，因为前者丢弃了许多数据，后者添加了许多数据。注意的是过采样不能随意对正例样本重复采样，会导致过拟合，过采样的代表性算法SMOTE通过对训练集里的正例进行插值产生额外的正例。另一方面，欠采样也不能随意丢弃数据，可能会丢失重要信息，欠采样的代表性算法EasyEnsemble则是利用集成学习机制，将反例划分为若干个几个供不同学习器使用，这样对每个学习器都进行欠采样，但在全局来看不会丢失重要信息。 值的一题的是，“再缩放”是“代价敏感学习”的基础。</p>
<p>　　</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag"># 机器学习</a>
          
            <a href="/tags/线性模型/" rel="tag"># 线性模型</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/11/30/DeepTesla/" rel="next" title="MIT 6.S094：DeepTesla">
                <i class="fa fa-chevron-left"></i> MIT 6.S094：DeepTesla
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/01/10/ml-1/" rel="prev" title="机器学习总结（一）：机器学习基础">
                机器学习总结（一）：机器学习基础 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">HF</p>
              <p class="site-description motion-element" itemprop="description">机器学习 MachineLearning</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          <div class="links-of-author motion-element">
            
          </div>

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#基本形式"><span class="nav-number">1.</span> <span class="nav-text">1.基本形式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#线性回归"><span class="nav-number">2.</span> <span class="nav-text">2.线性回归</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#对数几率回归"><span class="nav-number">3.</span> <span class="nav-text">3.对数几率回归</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#线性判别分析lda"><span class="nav-number">4.</span> <span class="nav-text">4.线性判别分析（\(LDA\)）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#符号"><span class="nav-number">4.1.</span> <span class="nav-text">符号</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#优化目标"><span class="nav-number">4.2.</span> <span class="nav-text">优化目标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#类内散度矩阵"><span class="nav-number">4.3.</span> <span class="nav-text">类内散度矩阵</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#类间散度矩阵"><span class="nav-number">4.4.</span> <span class="nav-text">类间散度矩阵</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#优化"><span class="nav-number">4.5.</span> <span class="nav-text">优化</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#多分类学习"><span class="nav-number">5.</span> <span class="nav-text">5.多分类学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#类别不平衡问题"><span class="nav-number">6.</span> <span class="nav-text">6.类别不平衡问题</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">HF</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.3</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  


</body>
</html>
