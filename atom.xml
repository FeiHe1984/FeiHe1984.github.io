<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>月六象棋</title>
  
  <subtitle>机器学习和人工智能</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-08-18T07:51:26.668Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>HF</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>机器学习总结（二）：线性模型</title>
    <link href="http://yoursite.com/2018/02/14/ml-2_1Linear/"/>
    <id>http://yoursite.com/2018/02/14/ml-2_1Linear/</id>
    <published>2018-02-13T16:00:00.000Z</published>
    <updated>2018-08-18T07:51:26.668Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/img/md-2/1.jpg" style="zoom:80%"></p><p>　　<strong>机器学习的相关知识系统的总结一遍，以便复习和加深印象。第二次更新线性模型相关内容：包括线性回归、对数几率回归、线性判别分析（<span class="math inline">\(LDA\)</span>）等。</strong></p><h2 id="基本形式">1.基本形式</h2><p>　　对于给定<span class="math inline">\(d\)</span>个属性描述的示例<span class="math inline">\(x\)</span> =（<span class="math inline">\(x_1\)</span>，<span class="math inline">\(x_2\)</span>，...，<span class="math inline">\(x_d\)</span>）,通过属性的线性组合来进行预测。一般的写法如下：</p><p>　　<span class="math display">\[f\left( x\right) =w^{T}x+b\]</span></p><p>　　线性模型具有很好的<strong>解释性</strong>（understandability，comprehensibility），参数<span class="math inline">\(w\)</span>代表每个属性在回归过程中的重要程度。 <a id="more"></a></p><h2 id="线性回归">2.线性回归</h2><p>　　线性回归（linear regression）试图试图学习到一个线性模型以尽可能准确的预测实值输出标记。</p><p>　　对于简单的单变量（只有一个属性<span class="math inline">\(x\)</span>）问题，则线性回归试图学得：<span class="math inline">\(f\left( x_{i}\right) =wx_{i}+b\)</span>，使得<span class="math inline">\(f\left( x_{i}\right) \simeq y\left( i\right)\)</span>。可以使用”最小二乘法“（试图找到一条直线，使得所有样本到直线上的欧氏距离之和最小），求导得到<span class="math inline">\(w\)</span>,<span class="math inline">\(b\)</span>的值。（具体步骤见西瓜书54页）</p><p>　　对于多变量（有<span class="math inline">\(d\)</span>个属性）问题，线性回归试图学得：<span class="math inline">\(f\left( x_{i}\right) =w^{T}x_{i}+b\)</span><span class="math inline">\(，使得\)</span><span class="math inline">\(f\left( x_{i}\right) \simeq y\left( i\right)\)</span>。可以使用“最小二乘法”（把<span class="math inline">\(w\)</span>,<span class="math inline">\(b\)</span>吸入向量模式<span class="math inline">\(\widehat {w}{\ast }\)</span>，使用正规方程求得 <span class="math inline">\(\widehat {w}{\ast }=\left( X^{T}X\right) ^{-1}X^{T}y\)</span> 求得相应的<span class="math inline">\(w\)</span>,<span class="math inline">\(b\)</span>的值。（具体步骤见西瓜书及吴恩达机器学习课程）</p><h2 id="对数几率回归">3.对数几率回归</h2><p>　　找一个单调可微函数将分类任务的真实标记<span class="math inline">\(y\)</span>与线性回归模型的预测值联系起来。</p><p>　　对于二分类任务，输出标记为<span class="math inline">\(y\in \left\{ 0,1\right\}\)</span>，而线性回归的预测结果<span class="math inline">\(h\left( x\right) =w^{T}x+b\)</span>，很明显是一个连续值，所以需要将其转换<strong>0/1</strong>值。所以要用到<strong>单位阶越函数</strong>：</p><p><span class="math display">\[y=\begin{cases}0,h\left( x\right) &lt;0;\\ 0\cdot 5,h\left( X\right) =0;\\ 1,h\left( x\right) &gt;0\end{cases}\]</span></p><p>即，若预测值大于0，就判为正例；若预测值小于0，就判为负例；临界值处，任意判别。 阶跃函数不可导，不连续，而<strong>广义线性回归模型</strong>（<span class="math inline">\(y=g^{-1}\left( w^{T}x+b\right)\)</span>）必须是一个可微的函数，需要找一个连续函数代替阶跃函数。 常用<strong>对数几率函数</strong>（logistic function）来进行替代：</p><p><span class="math display">\[y=\dfrac {1}{1+e^{-z}}\]</span></p><p>画出图形会看到它形似S，所以也是一种sigmoid函数。把对数几率函数代入到广义线性回归的公式中：</p><p><span class="math display">\[y=\dfrac {1}{1+e^{-\left( w^{T}x+b\right) }}\]</span></p><p>做一些化简，可以得到：</p><p><span class="math display">\[\ln \left( \dfrac {y}{1-y}\right) =w^{T}x+b\]</span></p><p>其中，<span class="math inline">\(y\)</span>是正例的可能性，<span class="math inline">\(1-y\)</span>是负例的可能性。 那么，这个<span class="math inline">\(\ln\left( \dfrac {y}{1-y}\right)\)</span>其实就是“对数几率”，可以看出，对数几率回归实质上就是使用线性回归模型<span class="math inline">\(w^{T}x+b\)</span>来逼近这个对数几率<span class="math inline">\(\ln\left(\dfrac {y}{1-y}\right)\)</span>。</p><p>　　如何求解出这个模型中的未知参数<span class="math inline">\(w\)</span>和<span class="math inline">\(b\)</span>呢？只考虑二分类的情况下，将y换成后验概率<span class="math inline">\(P( y= 1|x)\)</span>来表示，同理1-y可以换成<span class="math inline">\(P( y= 0|x)\)</span>。 则有：</p><p><span class="math display">\[\begin{cases}\ln \left(  \dfrac {P( y= 1|x)}{P( y= 0|x)}\right) =w^{T}x+b\\ P( y= 1|x) +P( y= 0|x) = 1\end{cases}\]</span></p><p>解得：</p><p><span class="math display">\[\begin{cases}\ P( y= 1|x) = \dfrac {e^{w^{T}x+b}}{1+e^{w^{T}x+b}}\\ P( y= 0|x) = \dfrac 1{1+e^{w^{T}x+b}}\end{cases}\]</span></p><p>通过极大似然法来估计<span class="math inline">\(w\)</span>和<span class="math inline">\(b\)</span>：</p><p><span class="math display">\[L\left( w,b\right) =\sum ^{n}_{i=1}\ln \left( P\left( y_{i}|x_{i};w,b\right) \right)\]</span></p><p>为表述方便，使用一个新矩阵<span class="math inline">\(β\)</span>来表示<span class="math inline">\(w\)</span>和<span class="math inline">\(b\)</span>，令<span class="math inline">\(\beta =\left( w;b\right)\)</span>。同时也要给<span class="math inline">\(x\)</span>矩阵补上一列<span class="math inline">\(1\)</span>，令<span class="math inline">\(\widehat {x}=\left( x;1\right)\)</span>。那么，<span class="math inline">\(w^{T}x+b=\beta ^{T}\widehat {x}\)</span>。由于是二分类，即只有<span class="math inline">\(y=0\)</span>和<span class="math inline">\(y=1\)</span>的情况，那么可以将似然项重写为<span class="math inline">\(y=0\)</span>和<span class="math inline">\(y=1\)</span>的情况相加：</p><p><span class="math display">\[P\left( y_{i}|x_{i};w,b\right) =y_{i}P_{1}\left( \widehat {x}_{i};\beta \right) +\left( 1-y_{i}\right) P_{0}\left( \widehat {x}_{i};\beta \right) \]</span></p><p>将上式代入到前面极大似然的公式中,并联立<span class="math display">\[\begin{cases}\ P( y= 1|x) = \dfrac {e^{w^{T}x+b}}{1+e^{w^{T}x+b}}\\ P( y= 0|x) = \dfrac 1{1+e^{w^{T}x+b}}\end{cases}\]</span>得到最后的结果：</p><p><span class="math display">\[L\left( \beta\right) =\sum ^{m}_{i=1}\left( y_{i}\beta ^{T}\widehat {x}_{i}-\ln \left( 1+e^{\beta ^{T}\widehat {x}_{i}}\right) \right)\]</span></p><p>最大化上式等价于最小化：</p><p><span class="math display">\[L\left( \beta\right) =\sum ^{m}_{i=1}\left( -y_{i}\beta ^{T}\widehat {x}_{i}+\ln \left( 1+e^{\beta ^{T}\widehat {x}_{i}}\right) \right)\]</span></p><p>也就是求得<span class="math inline">\(\beta ^{\ast }=\arg \min _{\beta }L\left( \beta \right)\)</span>，即求得<span class="math inline">\(\beta ^{\ast }\)</span>的值使得函数<span class="math inline">\(L\left( \beta \right)\)</span>最小。最后可以通过凸优化中的梯度下降法、牛顿法等方法来求出<span class="math inline">\(L\left( \beta \right)\)</span>函数的最优解<span class="math inline">\(\beta ^{\ast }\)</span>。</p><h2 id="线性判别分析lda">4.线性判别分析（<span class="math inline">\(LDA\)</span>）</h2><p>　　思想：给定训练样例集，设法将样例投影到一条直线上，使同类的投影点尽可能接近、异类样例的投影点尽肯能远离；在对新样本进行分类时，将其投影到同样的这条直线上，根据投影点的距离来确定新样本的类别。</p><h3 id="符号">符号</h3><ul><li><span class="math inline">\(x\)</span>：表示训练样本（列向量）</li><li><span class="math inline">\(x^{j}_{i}\)</span>：表示第<span class="math inline">\(i\)</span>类中的第<span class="math inline">\(j\)</span>个样本</li><li><span class="math inline">\(C\)</span>：表示有<span class="math inline">\(C\)</span>类样本</li><li><span class="math inline">\(\mu _{i}\)</span>：表示第<span class="math inline">\(i\)</span>类训练样本的均值 （<span class="math inline">\(i\)</span>=<span class="math inline">\(1\)</span>,<span class="math inline">\(2\)</span>,…,<span class="math inline">\(C\)</span>）</li><li><span class="math inline">\(M_{i}\)</span>：表示第<span class="math inline">\(i\)</span>类训练样本的数目</li><li><span class="math inline">\(M\)</span>：示训练样本的总数目 <span class="math inline">\(M = \sum^{C}_{i = 0}M_{i}\)</span></li><li><span class="math inline">\(\mu\)</span>：是所有样本的均值向量</li><li><span class="math inline">\(D_{i}\)</span>：表示第<span class="math inline">\(i\)</span>类样本集合</li><li><span class="math inline">\(S_{w}\)</span>：表示类内散度矩阵（<strong>within-class scatter matrix</strong>）</li><li><span class="math inline">\(S_{b}\)</span>：表示类间散度矩阵（<strong>between-class scatter matrix</strong>）</li></ul><h3 id="优化目标">优化目标</h3><p>　　将数据点投影到直线上（可能是多条直线），直线的函数解析式又称为线性函数。通常直线的表达式为:</p><p><span class="math display">\[y=w^{T}x\]</span></p><p><span class="math inline">\(x\)</span>就是样本向量（列向量），如果投影到一条直线上<span class="math inline">\(w\)</span>就是一个特征向量（列向量形式）或者多个特征向量构成的矩阵。<span class="math inline">\(y\)</span>为投影后的样本点（列向量）。将数据投影到直线<span class="math inline">\(w\)</span>上，则两类样本的中心在直线上的投影分别为<span class="math inline">\(w^{T}u_{0}\)</span>和<span class="math inline">\(w^{T}u_{1}\)</span>，若将所有的样本点都都投影到直线上，则两类样本的协方差分别为<span class="math inline">\(w^{T}\Sigma _{0}w\)</span>和<span class="math inline">\(w^{T}\Sigma _{1}w\)</span> 。</p><p>　　欲使同类样例的投影点尽可能接近，可以让同类样本点的协方差矩阵尽可能小，即<span class="math inline">\(w^{T}\Sigma _{0}w + w^{T}\Sigma _{1}w\)</span> 尽可能小; 而欲使异类样例的投影点尽可能远离，可以让类中心之间的距离尽可能大，即<span class="math inline">\(||w^{T}u_{0}-w^{T}u_{1}||^2 _{2}\)</span> 尽可能大。同时考虑二者，则可得到欲最大化的目标：</p><p><span class="math display">\[J=\dfrac {||w^{T}u_{0}-w^{T}u_{1}||^2 _{2}}{w^{T}\left( \Sigma _{0}+\Sigma _{1}\right) w} = \dfrac {w^{T}(u_{0}-u_{1})(u_{0}-u_{1})^Tw}{w^{T}\left( \Sigma _{0}+\Sigma _{1}\right) w}\]</span></p><h3 id="类内散度矩阵">类内散度矩阵</h3><p>　　对于两类问题而言：</p><p><span class="math display">\[S_{w}=\Sigma _{0}+\Sigma _{1}=\sum _{x\in D_{0}}\left( x-\mu _{0}\right) \left( x-\mu _{0}\right) ^{T} + \sum _{x\in D_{1}}\left( x-\mu _{1}\right) \left( x-\mu _{1}\right) ^{T}\]</span></p><p>　　对于多类问题而言：</p><p><span class="math display">\[S_{w}=\sum ^{C}_{i=i}\sum ^{M_{i}}_{j=1}\left( x^{j}_{i}-\mu _{i}\right) \left( x^{j}_{i}-\mu _{i}\right) ^{T}\]</span></p><p>其中：</p><p><span class="math display">\[\sum ^{M_{i}}_{j=1}\left( x^{j}_{i}-\mu _{i}\right) \left( x^{j}_{i}-\mu _{i}\right) ^{T}\]</span></p><p>表示第<span class="math inline">\(i\)</span>类样本的协方差矩阵。所以<span class="math inline">\(S_w\)</span>就是表示<span class="math inline">\(C\)</span>类样本协方差矩阵之和。</p><h3 id="类间散度矩阵">类间散度矩阵</h3><p>　　对于两类问题而言：</p><p><span class="math display">\[S_{b}=\left( \mu _{0}-\mu_{1}\right)\left( \mu _{0}-\mu_{1}\right)  ^{T}\]</span></p><p>　　对于多类问题而言：</p><p><span class="math display">\[S_{b}=\sum ^{C}_{i=i}\left( \mu _{i}-\mu\right)\left( \mu _{i}-\mu\right)  ^{T}\]</span></p><p><span class="math inline">\(S_b\)</span>表示各个类样本均值的协方差矩阵。</p><h3 id="优化">优化</h3><p>　　定义过类内散度矩阵和类间散度矩阵后，我们可以将上述的优化目标重新写为：</p><p><span class="math display">\[J= \dfrac {w^{T}S_{b}w}{w^{T}S_{w}w}\]</span></p><p>这就是<span class="math inline">\(LDA\)</span>欲最大化的目标，即<span class="math inline">\(S_b\)</span>与<span class="math inline">\(S_w\)</span>的广义瑞利商。如何确定<span class="math inline">\(w\)</span>呢？注意到上式的分子和分母都是关于<span class="math inline">\(w\)</span>的二次项，因此上式的解与<span class="math inline">\(w\)</span>的长度无关,只与其方向有关.不失一般性，令<span class="math inline">\(w^{T}S_{w}w=1\)</span>,则上式等价于：</p><p><span class="math display">\[min_w  -w^{T}S_{b}w\]</span></p><p><span class="math display">\[st. w^{T}S_{w}w=1\]</span></p><p>使用拉格朗日乘子法，可得：</p><p><span class="math display">\[c\left( w\right) =w^{T}S_{b}w-\lambda \left( w^{T}S_{w}w-1\right)\]</span></p><p><span class="math display">\[\dfrac {dc}{dw}=2S_{b}w-2\lambda S_{w}w=0\]</span></p><p><span class="math display">\[S_{b}w = \lambda S_{w} w\]</span></p><p><span class="math display">\[S^{-1}_{w}S_{b}w=\lambda w\]</span></p><p><span class="math inline">\(w\)</span>的闭式解则是<span class="math inline">\(S^{-1}_{w}S_{b}\)</span>的<span class="math inline">\(N-1\)</span>个最大广义特征值所对应的特征向量组成的矩阵。若将<span class="math inline">\(w\)</span>视为一个投影矩阵，则多分类<span class="math inline">\(LDA\)</span>将样本投影到<span class="math inline">\(N-1\)</span>维空间，从而减小样本点的维数，且投影过程中使用的类别信息，因此<span class="math inline">\(LDA\)</span>被视为一种经典的监督降维方法。</p><h2 id="多分类学习">5.多分类学习</h2><p>　　多分类学习的基本思路是“拆解法”，即将多分类任务拆为若干个二分类任务求解。具体来说，先对问题进行拆分，然后为拆除的每个二分类任务训练一个分类器；在测试时，对这些分类器的预测结果进行集成以获得最终的多分类结果。关键问题：<strong>拆分</strong>和<strong>集成</strong>。</p><p>　　最经典的拆分策略有三种：“一对一(OvO)”、“一对其余(OvR)”、”多对多(MvM)”。</p><ul><li>OvO:将<span class="math inline">\(N\)</span>个类别两两匹配，从而产生<span class="math inline">\(N(N−1)/2\)</span>个二分类器。将新样本提交给所有的分类器，得到了<span class="math inline">\(N(N−1)/2\)</span>个结果，最终结果通过投票产生。N比较大的时候，代价还是很高。</li><li>OvR:每次将一个类作为样例的正例，其他所有均作为反例，得到<span class="math inline">\(N\)</span>个分类器。提交新的样本同时也得到<span class="math inline">\(N\)</span>个结果，最终结果通过投票产生。</li><li>MvM:每次将若干个类作为正例、若干个类作为反例。显然OvO、OvR都是其特例。MvM的正、反类设计必须有特殊的设计，常用的一种技术：”纠错输出码”，简称ECOC。 ECOC是将编码的思想引入类别的划分，并可能在解码过程中具有容错性。ECOC工作过程主要分为两步：</li><li>编码：对N个类做M次划分，每次划分将一部分作为正类，一部分划分反类，从而形成一个二分类训练集。一共产生M个训练集，训练出M个分类器。</li><li>解码：M个分类器分别对测试样本进行预测，这些预测标记组成一个编码。将这个预测编码与每个类各自的编码进行比较，返回其中距离最小的类别作为最终结果。</li><li>对同一个学习任务来说，ECOC编码越长，纠错能力越强。然而编码越长所需要的训练的分类器越多，计算存储开销都会增大；另一方面对于有限类别码长超过一定范围就没有意义了。对于同等长度的编码，理论上来说，任务两个类别之间的编码距离越远，则纠错能力越强。</li></ul><h2 id="类别不平衡问题">6.类别不平衡问题</h2><p>　　类别不平衡就是指分类任务中不同类别的训练样例数目差别很大的情况。</p><p>　　从线性分类器角度考虑，利用<span class="math inline">\(y=w^Tx+b\)</span>对新样本<span class="math inline">\(x\)</span>做分类，若<span class="math inline">\(y&gt;0.5\)</span>即为正例，否则为反例。几率<span class="math inline">\(\dfrac{y}{1-y}\)</span>正反映了正例可能性和反例可能性的比值，那么分类器的决策规则为:<span class="math inline">\(\dfrac{y}{1-y} &gt; 1\)</span>则预测为正例。</p><p>　　然而，当训练集正、反例数量不同时，令<span class="math inline">\(m^+\)</span>表示正例数目，<span class="math inline">\(m^−\)</span>表示反例数目，则观测几率是<span class="math inline">\(\dfrac {m^+}{m^-}\)</span>，由于训练是对真实样本的无偏采样，因此观测几率就代表了真实几率，于是只要分类器的预测几率高于观测记录就应判为正例，即<span class="math inline">\(\dfrac{y}{1-y} &gt; \dfrac{m^+}{m^-}\)</span>则预测为正例。这时候就可以令<span class="math inline">\(\dfrac {y^`}{1-y^`} =\dfrac{y}{1-y}\times\dfrac{m^+}{m^-}\)</span>，这就是类别不平衡的一个基本策略—“再缩放”。</p><p>　　在缩放思想虽简单，但实际操作并不平凡，主要因为“训练集是真实样本总体的无偏采样”这个假设往往不成立，也就是说，未必能有效地基于训练集观测几率来推断出真实几率。在这种情况下，现有技术大体有三种做法（假定正类样例少，反类样例多）：第一类是直接对训练集例的反类样例进行“欠采样”，即除去一些反例样本，使正反接近。第二类是对训练集中的正类样本进行“过采样”，即增加一些正例样本，使正反接近。第三类是直接基于原始数据训练集进行学习，但在应训练好的分类器进行预测时，将再缩放策略嵌入其决策过程中，称为“阀值移动”。</p><p>　　欠采样的时间开销通常远小于过采样，因为前者丢弃了许多数据，后者添加了许多数据。注意的是过采样不能随意对正例样本重复采样，会导致过拟合，过采样的代表性算法SMOTE通过对训练集里的正例进行插值产生额外的正例。另一方面，欠采样也不能随意丢弃数据，可能会丢失重要信息，欠采样的代表性算法EasyEnsemble则是利用集成学习机制，将反例划分为若干个几个供不同学习器使用，这样对每个学习器都进行欠采样，但在全局来看不会丢失重要信息。 值的一题的是，“再缩放”是“代价敏感学习”的基础。</p><p>　　</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/img/md-2/1.jpg&quot; style=&quot;zoom:80%&quot;&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;机器学习的相关知识系统的总结一遍，以便复习和加深印象。第二次更新线性模型相关内容：包括线性回归、对数几率回归、线性判别分析（&lt;span class=&quot;math inline&quot;&gt;\(LDA\)&lt;/span&gt;）等。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;基本形式&quot;&gt;1.基本形式&lt;/h2&gt;
&lt;p&gt;　　对于给定&lt;span class=&quot;math inline&quot;&gt;\(d\)&lt;/span&gt;个属性描述的示例&lt;span class=&quot;math inline&quot;&gt;\(x\)&lt;/span&gt; =（&lt;span class=&quot;math inline&quot;&gt;\(x_1\)&lt;/span&gt;，&lt;span class=&quot;math inline&quot;&gt;\(x_2\)&lt;/span&gt;，...，&lt;span class=&quot;math inline&quot;&gt;\(x_d\)&lt;/span&gt;）,通过属性的线性组合来进行预测。一般的写法如下：&lt;/p&gt;
&lt;p&gt;　　&lt;span class=&quot;math display&quot;&gt;\[f\left( x\right) =w^{T}x+b\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　线性模型具有很好的&lt;strong&gt;解释性&lt;/strong&gt;（understandability，comprehensibility），参数&lt;span class=&quot;math inline&quot;&gt;\(w\)&lt;/span&gt;代表每个属性在回归过程中的重要程度。
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="线性模型" scheme="http://yoursite.com/tags/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>机器学习总结（一）：机器学习基础</title>
    <link href="http://yoursite.com/2018/01/10/ml-1/"/>
    <id>http://yoursite.com/2018/01/10/ml-1/</id>
    <published>2018-01-09T16:00:00.000Z</published>
    <updated>2018-08-18T07:23:42.237Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/img/md-1/1.jpg" style="zoom:70%"></p><p>　　<strong>机器学习的相关知识系统的总结一遍，以便复习和加深印象。第一次更新关于机器学习基础方面相关内容：包括机器学习概念、评估指标、纬度灾难等。</strong></p><h2 id="什么是机器学习">1. 什么是机器学习？</h2><ul><li>机器学习算法可以从过去已知的数据中学习数据隐藏的规律，利用这些学习来的规律，在给定一定输入的情况下，对未来进行预测。 --米歇尔(Mitchell,T.M.)</li><li>机器学习使得计算机不需要显示的编程，而自己学习模型的科学。 --吴恩达</li><li>机器学习是一种帮助数据科学家从已知数据中预测行为、结果和趋势的一种技术。 --微软 <a id="more"></a></li></ul><h2 id="评估指标">2. 评估指标</h2><p>　　监督学习可分为两类，分类和回归问题，相对应有不同的模型评判标准</p><h3 id="分类">分类</h3><p>　　首先说分类问题会出现的4种情况：</p><p>　　1）True positive (TP): 将正类预测为正类，真阳</p><p>　　2）True negative (TN): 将负类预测为负类，真阴</p><p>　　3）False negative (FN):将正类预测为负类，伪阴</p><p>　　4）False positive (FP): 将负类预测为正类，伪阳</p><p>　　如下图所示：</p><p><img src="/img/md-1/2.jpg" style="zoom:70%"></p><h4 id="accuracy-准确率">Accuracy 准确率</h4><p>　　<span class="math display">\[A\left( m\right) =\dfrac {TN+TP}{TN+TP+FP+FN}\]</span></p><p>　　准确率的定义是对于给定的测试数据集，分类器正确分类的样本数与总样本数之比。Accuracy优点很明显，那就是简单直观，但是accuracy有时会陷入Accuracy paradox中。即准确率越高并不代表模型越好。</p><h4 id="precision-精确率">Precision 精确率</h4><p>　　<span class="math display">\[P\left( m\right) =\dfrac {TP}{TP+FP}\]</span></p><p>　　精确率计算的是所有&quot;正确被检索的item&quot;占所有&quot;实际被检索到的&quot;的比例。</p><h4 id="recall-召回率">Recall 召回率</h4><p>　　<span class="math display">\[R\left( m\right) =\dfrac {TP}{TP+FN}\]</span></p><p>　　召回率计算的是所有&quot;正确被检索的item&quot;占所有&quot;应该检索到的item&quot;的比例。</p><h4 id="f1-score">F1 Score</h4><p>　　<span class="math display">\[\dfrac {2}{F1}=\dfrac {1}{P}+\dfrac {1}{R}\]</span></p><p>　　F1 值是精确率和召回率的调和均值。</p><h4 id="适用场景">适用场景</h4><p>　　精确率和召回率是互相影响的，理想情况下肯定是做到两者都高，但是一般情况下精确率高、召回率就低，召回率低、精确率高，当然如果两者都低，那是什么地方出问题了。当精确率和召回率都高时，F1的值也会高。在两者都要求高的情况下，可以用F1来衡量。</p><h4 id="roc-与-auc">ROC 与 AUC</h4><p>　　ROC全称是“受试者工作特征”（Receiver Operating Characteristic）。ROC曲线的面积就是AUC（Area Under the Curve）。AUC用于衡量“二分类问题”机器学习算法性能（泛化能力）。</p><p>　　样本中的真实正例类别总数即TP+FN。<code>TPR</code>即True Positive Rate: <span class="math display">\[TPR=\dfrac {TP}{TP+FN}\]</span></p><p>　　同理，样本中的真实反例类别总数为FP+TN。<code>FPR</code>即False Positive Rate: <span class="math display">\[FPR=\dfrac {FP}{TN+FP}\]</span></p><p>　　还有一个概念叫”截断点”。机器学习算法对test样本进行预测后，可以输出各test样本对某个类别的相似度概率。比如t1是P类别的概率为0.3，一般我们认为概率低于0.5，t1就属于类别N。这里的0.5，就是”截断点”。</p><p>　　总结一下，对于计算ROC，最重要的三个概念就是<code>TPR</code>, <code>FPR</code>, <code>截断点</code>。<code>截断点</code>取不同的值，<code>TPR</code>和<code>FPR</code>的计算结果也不同。将<code>截断点</code>不同取值下对应的<code>TPR</code>和<code>FPR</code>结果画于二维坐标系中得到的曲线，就是ROC曲线。横轴用FPR表示。</p><p>　　<strong>AUC</strong>值是一个概率值，当你随机挑选一个正样本以及负样本，当前的分类算法根据计算得到的Score值将这个正样本排在负样本前面的概率就是AUC值，AUC值越大，当前分类算法越有可能将正样本排在负样本前面，从而能够更好地分类。</p><h3 id="回归">回归</h3><h4 id="mean-absolute-errormae">Mean Absolute Error(MAE)</h4><p>　　MAE用来描述预测值和真实值的差值。数值越小越好。</p><p>　　假设<span class="math inline">\(y_i\)</span>是真实值，<span class="math inline">\(f_i\)</span>是相对应的预测值，则n个样本的MAE可由下式出给：</p><p>　　<span class="math display">\[MAE=\dfrac {1}{n}\sum ^{n}_{i=1}\left| f_{i}-y_{i}\right|\]</span></p><h4 id="mean-squared-errormse">Mean Squared Error(MSE)</h4><p>　　Mean Squared Error也称为Mean Squared Deviation(MSD)，计算的是预测值和实际值的平方误差。同样，数值越小越好。</p><p>　　假设<span class="math inline">\(y_{i}\)</span>是真实值，<span class="math inline">\(f_{i}\)</span>是相对应的预测值，则n个样本的MSE可由下式出给：</p><p>　　<span class="math display">\[MSE=\dfrac {1}{n}\sum ^{n}_{i=1}\left( f_{i}-y_{i}\right) ^{2}\]</span></p><h4 id="r2-score"><span class="math inline">\(R^{2}\)</span> Score</h4><p>　　<span class="math inline">\(R^{2}\)</span> Score又称为the coefficient of determination。判断的是预测模型和真实数据的拟合程度，最佳值为1，同时可为负值。</p><p>　　假设<span class="math inline">\(y_{i}\)</span>是真实值，<span class="math inline">\(f_{i}\)</span>是相对应的预测值，则n 个样本的<span class="math inline">\(R^{2}\)</span> Score由下式公式给出：</p><p>　　<span class="math display">\[R^{2}=1-\dfrac {\sum ^{n}_{i=1}\left( y_{i}-f_{i}\right) ^{2}}{\sum ^{n}_{i=1}\left( y_{i}-\overline {y}\right) ^{2}}\]</span></p><p>　　其中<span class="math inline">\(\overline {y}\)</span>是<span class="math inline">\(y\)</span>的均值。</p><h2 id="误差的原因">3.误差的原因</h2><h3 id="bias偏差和variance方差">Bias（偏差）和Variance（方差）</h3><p>　　<strong>偏差Bias：</strong>描述的是预测值（估计值）的期望与真实值之间的偏离程度。偏差越大，越偏离真实数据。</p><p>　　<strong>方差Variance：</strong>描述的是预测值的变化范围，离散程度，也就是离其期望值的距离。方差越大，数据的分布越分散。</p><p>　　<strong>偏差和方差对误差Error的影响</strong>：<strong>Error = Bias + Variance + Noise</strong>。其中，<strong>Noise</strong>（噪声）是数据本身的问题，比如不准确的客户资料，在此不进行讨论。<strong>偏差</strong>（bias）造成的<strong>误差 - 准确率和欠拟合</strong>。如果模型具有足够的数据，但因不够复杂而无法捕捉基本关系，即如果模型不适当，则会出现偏差。这样一来，模型一直会系统地错误表示数据，从而导致预测准确率降低。出现欠拟合（underfitting）；<strong>方差</strong>（variance）造成的<strong>误差 - 精准度和过拟合</strong>。方差就是指模型过于贴近训练数据，以至于没办法把它的结果泛化（generalize）。而泛化是正事机器学习要解决的问题，如果一个模型只能对一组特定的数据有效，换了数据就无效了，我们就说这个模型过拟合。用一张图表示：</p><p><img src="/img/md-1/3.jpg" style="zoom:100%"></p><h2 id="维度灾难">4.维度灾难</h2><p>　　当维数提高时，模型空间的体积提高太快，因而可用数据变得很稀疏。在高维空间中，所有的数据都很稀疏，从很多角度看都不相似，因而平常使用的数据组织策略变得极其低效。为了获得在统计学上正确并且有可靠的结果，用来支撑这一结果所需要的数据量通常随着维数的提高而呈指数级增长。</p><p>　　<strong>如何避免维度灾难</strong>：实际上并没有一种固定的方法避免维度灾难，解决方法需要结合数据集和所选的模型。训练数据集越小，则用到的特征（feature）应当越少。另外，对于诸如神经网络，kNN，决策树等泛化不好容易过拟合的分类器，维度应当适当的减少。而对于朴素贝叶斯和线性分类器等不太复杂的分类器，特征可以适当的增大。</p><h2 id="k折-交叉验证-k-fold-cross-validation">5.K折-交叉验证 K-fold Cross Validation</h2><p>　　初始采样分割成K个子样本，一个单独的子样本被保留作为验证模型的数据，其他K-1个样本用来训练。交叉验证重复K次，每个子样本验证一次，平均K次的结果或者使用其它结合方式，最终得到一个单一估测。这个方法的优势在于，同时重复运用随机产生的子样本进行训练和验证，每次的结果验证一次。方差Variance随着k的增大而减小。</p><p><img src="/img/md-1/4.jpg" style="zoom:100%"></p><h2 id="网格搜索">6.网格搜索</h2><p>　　预测模型有很多Hyper-parameters，如何知道超参数的哪些组合可以达到更好的效果呢？scikit learn提供了网格搜索的算法。只需要设定需要调整的参数和参数的范围，算法会自动验证每一种参数组合的验证效果。</p><p><img src="/img/md-1/5.jpg" style="zoom:70%"></p><p>对SVM的C参数和gamma的网格搜索可视化结果如上图所示，可知{C=1.0，gamma = 0.1}时效果最好。</p><h2 id="references">References：</h2><ol style="list-style-type: decimal"><li>周志华 《机器学习》</li><li>李航 《统计学习方法》</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/img/md-1/1.jpg&quot; style=&quot;zoom:70%&quot;&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;机器学习的相关知识系统的总结一遍，以便复习和加深印象。第一次更新关于机器学习基础方面相关内容：包括机器学习概念、评估指标、纬度灾难等。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;什么是机器学习&quot;&gt;1. 什么是机器学习？&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;机器学习算法可以从过去已知的数据中学习数据隐藏的规律，利用这些学习来的规律，在给定一定输入的情况下，对未来进行预测。 --米歇尔(Mitchell,T.M.)&lt;/li&gt;
&lt;li&gt;机器学习使得计算机不需要显示的编程，而自己学习模型的科学。 --吴恩达&lt;/li&gt;
&lt;li&gt;机器学习是一种帮助数据科学家从已知数据中预测行为、结果和趋势的一种技术。 --微软
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="机器学习基础" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>MIT 6.S094：DeepTesla</title>
    <link href="http://yoursite.com/2017/11/30/DeepTesla/"/>
    <id>http://yoursite.com/2017/11/30/DeepTesla/</id>
    <published>2017-11-30T03:34:12.000Z</published>
    <updated>2017-12-12T09:34:22.025Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/img/tesla.jpg" alt="tesla"> 　　<strong>前段时间完成了MIT 6.S094：DeepTesla的小项目（用深度学习预测特斯拉转向角度），做了个总结，分享给大家。</strong> <a id="more"></a></p><h1 id="i.-问题的定义">I. 问题的定义</h1><h2 id="项目概述">1.1 项目概述</h2><h3 id="项目背景">1.1.1 项目背景</h3><p>　　近年来，深度学习神经网络在计算机视觉领域，特别是图像识别上取得的突破性进展无疑是科技界的热点之一。诚然，神经网络并非新兴技术，从时间线上可以看出它的发展脉络：1958年康奈尔心理学家罗森布拉特推出感知机；1963年，弗拉基米尔·万普尼克在他的书《支持向量机》中首次发表反向传播算法；1986年Hinton等人发明训练多重神经网络纠错的方法；1989年LeCun用卷积神经网络识别手写体；1991年递归神经网络发明；2007年李飞飞创立ImageNet；2012年谷歌大脑识别猫脸（6月），8月谷歌将神经网络引入语音识别，10月Hinton的学生在ImageNet竞赛夺冠，成绩大幅提升；2015年12月微软ResNet图像识别准确率超越人类。在将近50年的发展历史中，其迎来爆发的根本原因就在于现今计算机强大的计算力和海量的数据。现在，这项技术已经延伸到医疗、游戏、公共服务等等和人们生活息息相关的各个层面之中。</p><p>　　在众多深度学习神经网络应用场景之中，无人驾驶（自动驾驶）无疑是中短期内最有前景的之一。现阶段，以摄像头作为道路图像传感器，结合人工智能和视觉处理技术实现无人驾驶（自动驾驶）在成本上体现了巨大的优势。不同的神经网络模型已经应用到车辆转向控制和速度控制中。如英伟达（NVIDIA）提出的端到端<a href="#1">[1]</a>（ end to end）卷积神经网络模型（Convolutional Neural Network，以下简称CNN或ConvNet ）；Comma.ai提出的变分自动编码器<a href="#2">[2]</a>（Variational Autoencoder，以下简称VAE）及基于生成式对抗网络（GANgenerative adversarial network，以下简称GAN），用于实现道路视频预测的代价函数（Cost Function），在此基础上结合了递归神经网络（ Recurrent Neural Networks，以下简称RNN）的转换模型（Transition Model）；最近，在UDACITY的开源挑战项目&quot;Teaching a Machine to Steer a Car&quot;<a href="#3">[3]</a>，第一名的”Team Komanda“利用了循环神经网络序列到序列模型（RNN seq2seq, Recurrent Neural Networks Sequence to Sequence），使用CNN结合长短期记忆网络（Long Short-Term Memory，以下简称LSTM）实现了一个不同长度序列输入图像到输出转向角度的映射模型。</p><p>　　在这些已经实现的案列中，与传统的方法相比，神经网络和深度学习展现了惊人的效率和优势。本项目就是基于MIT 6.S094 这门公开课中的Tesla数据集训练深度学习模型，根据车辆的前置相机所拍摄的路况图像，实现对车辆转向角度的预测，从而对深度学习模型有一个初步的探索。</p><h3 id="数据集和输入">1.1.2 数据集和输入</h3><p>　　数据集包括tesla在两种不同驾驶模式（human driving和autopilot）下的前置相机录制的视频和车辆的转向控制信号。数据可以从这里下载:<a href="https://pan.baidu.com/s/1c2J2IFA" target="_blank" rel="noopener">百度云</a>，数据集包含10段H264/MKV格式视频，视频帧为30 fps，截取画面像素为1280 * 720，视频数据格式如图&quot;Figure 1: 视频帧图片&quot;：</p><div class="figure"><img src="/img/1.jpg" alt="1"><p class="caption">1</p></div><p>　　每一个视频都对应一张存储有对应时间戳（ts_micro）和帧编号（frame_index）和转向角度（wheel）的CSV格式表格。表格见“Table 1：CSV表格数据”。其中转向角度（wheel）中'+'表示顺时针，'-'表示逆时针。</p><table><thead><tr class="header"><th align="center">ts_micro</th><th align="center">frame_index</th><th align="center">wheel</th></tr></thead><tbody><tr class="odd"><td align="center">1464305394391807</td><td align="center">0</td><td align="center">-0.5</td></tr><tr class="even"><td align="center">1464305394425141</td><td align="center">1</td><td align="center">-0.5</td></tr><tr class="odd"><td align="center">1464305394458474</td><td align="center">2</td><td align="center">-0.5</td></tr></tbody></table><div align="center"><p>Table 1：CSV表格数据</p></div><p>　　在项目中，通过裁剪图像（去掉天空部分）、缩减像素采样原始数据得到了宽、高为80 * 80 的RGB图像，并将图像和转向角度以JPEG格式和CSV格式保存到硬盘中作为输入数据，具体步骤将在“数据预处理”章节进行详诉。</p><h2 id="问题陈述">1.2 问题陈述</h2><h3 id="问题描述">1.2.1 问题描述</h3><p>　　该项目的目的在于利用深度学习模型：端到端 NVIDIA end-to-end 卷积神经网络模型（CNN）；VGG16 + Nvidia 迁移学习（Transfer Learning）模型。根据车辆的前置相机所拍摄的路况图像，实现对车辆转向角度的预测，并评估模型的表现。</p><h3 id="问题定义">1.2.2 问题定义</h3><p>　　假设<span class="math inline">\(x_t\)</span>表示的是数据集的第t帧，<span class="math inline">\(X_t\)</span>是帧长为n的视频表示：<span class="math inline">\(X_t=\{x_{t-n+1}, x_{t-n+2},...x_t\}\)</span>，<span class="math inline">\(Y_t\)</span>表示对应对应帧长为n的转向角度：<span class="math inline">\(Y_t=\{y_{t-n+1}, y_{t-n+2},...y_t\}\)</span>，预测转向角度时定义估值函数<span class="math inline">\(F\)</span>：<span class="math inline">\(R^{80*80*3*n}\)</span>→<span class="math inline">\(R^{n}\)</span>，下一帧转向角度预测结果为 <span class="math inline">\(y_{t+1}\)</span>= <span class="math inline">\(F\)</span> ( <span class="math inline">\(x_{t+1}\)</span>)。</p><p>　　该项目的任务就是训练模型得到较好的估值函数<span class="math inline">\(F\)</span>，从而对预测视频帧的转向角度有一个比较准确的预测。</p><h2 id="评价指标">1.3 评价指标</h2><p>　　就整个项目来说，这是一个回归问题，均方误差（Mean Squared Error, MSE）可以作为评估指标。</p><div align="center"><p><span class="math display">\[MSE = \frac{1}{N} \sum_{N}^{i=1}(y_{p} - y)^2\]</span></p></div><p>　　其中， <span class="math inline">\(y_p\)</span>是预测的转向角度， <span class="math inline">\(y\)</span>是真实的转向角度，样本数量为<code>N</code>，均方误差低则模型表现优。</p><p>　　同时，要结合分析预测转向角度的时间序列图和人工转向角度的时间序列图的“贴合”程度（是否接近人工驾驶）来考虑哪一个模型表现更好。</p><h1 id="ii.-分析">II. 分析</h1><h2 id="数据的探索">2.1 数据的探索</h2><p>　　在初始对数据探索阶段，分别查看了单张测试图片和10段道路视频文件，对不同的驾驶场景进行了截图，&quot;Figure 2: 不同场景截图&quot;：从图中可以看出，视频帧包括不同的时段（如正午，傍晚）、不同的天气情况（如阴晴），不同的道路情况（如桥，林间路）等。视频通过前置相机拍摄，在底部可以看到车头以及相机阴影。查看了CSV格式表格数据，发现数据包含27000个样本，并且转向角度的数值在 [-18, 15] 区间。</p><div class="figure"><img src="/img/2.jpg" alt="1"><p class="caption">1</p></div><h2 id="探索性可视化">2.2 探索性可视化</h2><p>　　目标变量CSV表格中的转向角度，需要通过直方图查看其平衡性：如图&quot;Figure 3: 转向角度数据分布&quot;：可以看出，整个转向角度数据分布基本为正态分布，车辆的控制信号中角度为0附近的数据比较多，意味着得到的模型可能对比较大的转弯反应“迟钝”，解决方法则可以通过复制转向角度较大的数据以增加训练数据来解决，使得模型学到有价值的转向策略（一般情况，一个好的数据集应该是顺时针、逆时针、直行的转向信号频次足够接近的数据集，即“对称”的数据集。但从逻辑上，人类开车时需要转弯的频率是要远低于直行微调方向盘的频率，增加整体训练数据也可以让模型学到转弯的策略）。</p><div class="figure"><img src="/img/3.jpg" alt="1"><p class="caption">1</p></div><p>　　另外，需要查看转向角度在时间序列上的分布：如图“Figure 4: 转向角度的时间序列”：查看了前2700帧（90秒）图像的转向角度的时间序列，结合CSV表格可以看出，人工转向记录的数据是离散的，非连续的。但从逻辑上来说，它仍是求一个具体数值，而不是对这些角度分类，所以还是一个回归问题。</p><div class="figure"><img src="/img/4.jpg" alt="1"><p class="caption">1</p></div><p>　　最后，随机从一段视频中选择几帧查看一下人工转向角度是否合理，如图Figure 5。可以发现人工转向角度基本正确，幅度调整得当，说明驾驶员的驾驶策略是比较合理的，提供的数据可以用来训练。</p><div class="figure"><img src="/img/5.jpg" alt="1"><p class="caption">1</p></div><h2 id="算法和技术">2.3 算法和技术</h2><p>　　在该项目中涉及到的算法和技术有：端到端技术（end-to-end）、卷积神经网络（CNN）、迁移学习技术（Transfer Learning）。现分诉如下：</p><h3 id="端到端">2.3.1 端到端</h3><p>　　端到端的学习方法可以追溯到80年代后期<a href="#4">[4]</a> ，其方法可以简述为神经网络输入为原始图片，神经网络输出为直接控制的命令。其特点在于，特征提取层和控制输出层的分界并不明显，网络中的每一个部分对于系统来说都起着特征提取和控制作用。</p><h3 id="卷积神经网络">2.3.2 卷积神经网络</h3><p>　　为了引入端到端的技术，需要从原始图片提取相关信息（特征）。从效率和减少网络参数个数考虑，卷积神经网络（CNN）无疑是最佳选择。它的结构和普通神经网络（如图Figure 6(a)）都一样，其主要不同之处在于： CNN假定输入的是图片，根据图片的特性对网络进行设定以达到提高效率，减少计算参数量的目的。具体做法为：各个网络层将神经元安置到三维空间（width, height, depth），每个神经元接收一些输入，前向传播进行点积运算和选择性的使用非线性运算（如激活函数），然后使用反向传播算法更新权重（weights）和偏差（bias），可见图“Figure 6(b)”。在本项目中，红色输入层是维度为80 * 80 * 3（宽、高、RGB通道）的图片，输出则是转向角度数值。</p><div class="figure"><img src="/img/6.jpg" alt="1"><p class="caption">1</p></div><p>　　卷积神经网络有三种层：卷积层、池化层和全连接层（Convolutional Layer, Pooling Layer, 及 Fully-Connected Layer）。 卷积层由很多过滤器组成，每个过滤器都只有一小部分，每次只与原图像上的一小部分连接，每个过滤器在原图像滑动得到一个特征图（feature map），假如有k个过滤器则形成的特征图深度（depth）为k。这样，通过卷积层，就得到了新的三维的图像特征表示，通过权重共享大大提高了计算效率；池化pooling层，他是将卷积层得到的结果无重合的分成几部分，然后选择每一部分的最大值，或者平均值，或者2范数，或者其他的值，如图Figure 7。全连接层则是每一个神经元都与上一层的所有神经元相连，用来把前边提取到的特征综合起来。</p><div class="figure"><img src="/img/7.jpg" alt="1"><p class="caption">1</p></div><p>　　通过这三种网络层的依次连接，卷积网络就完成了原始图片到转向角度的映射，为了使模型有更好的表现，需要调整的参数有：1.对图片预处理的参数包括图像的尺寸和图像的感受区域范围；2.超参数：训练次数（number of epochs）， 批量大小（batch size），优化类型（ optimizer type），学习率（learning rate）；3.网络结构：网络层的数量，网络层的类型，网络层中的参数调节（参数的初始优化，激活函数等）。</p><h3 id="迁移学习">2.3.3 迁移学习</h3><p>　　迁移学习就是用大数据集（如ImageNet）训练过的卷积网络作为初始模型或者直接作为固定特征的提取器<a href="#5">[5]</a> ，即是说把预先训练好的模型，应用到类似的处理任务上，达到节约训练时间和提高模型表现的目的。以下是三种迁移学习的策略：1.训练好的卷积网络作为固定特征提取器（ConvNet as fixed feature extractor, train only the top-level of the network, the rest of the network remains fixed）。使用训练好的网络将最后一层全连接层（一般是分类用的）去掉或替换，然后将已经训练好的部分看做一个特征提取器；2.对卷积网络进行微调（ Fine-tuning the ConvNet, train the entire network end-to-end, start with pre-trained weights）。第二个策略是不仅对顶层的全连接层进行重新训练和替换，同时通过反向传播对已经训练好的卷积层参数进行微调。可以对所有网络层的参数都进行微调，也可以让前几层的参数固定（前几层一般包含通用特征的识别，如颜色、线条等），然后对高层部分进行微调（包含更多训练集的特征）；3.预训练模型（Pretrained models, train the entire network end-to-end, start from random weights）。使用别人发布的在大数据集（如ImageNet）训练卷积网络的checkpoints 进行重新的参数训练。策略2和策略3的区别在于2使用的是在训练好的权重上进行参数微调，而3需要在随机的参数权重上重新开始训练。</p><p>　　在本项目中，作为迁移学习的卷积网络为VGG16<a href="#6">[6]</a>，采用的策略为2：Fine-tuning（模型中称为fine-tuned，即参数微调）具体讨论见“III. 方法”章节。</p><h2 id="基准模型">2.4 基准模型</h2><p>　　本项目尝试了两种不同模型：第一种是英伟达（NVIDIA）提出的端到端（end-to-end）卷积神经网络模型（convolutional neural network），该模型将作为基准模型；第二种基于迁移学习（transfer learning）的VGG16 + Nvidia模型，该模型作为对比模型，对比模型将在下一章讨论。本质上两种模型都是一致的，使用卷积层提取特征，在加上全连接层进行回归预测。</p><p>　　基准模型Nvidia model参考了NVIDIA发表的一篇论文<a href="#1">[1]</a>提出的模型架构，该论文介绍如何利用卷积网络（CNNs）实现端到端的无人驾驶，具体模型见图如图Figure 8。简单分析一下该模型的结构：输入层接收是宽、高（200, 66）并且有3个颜色通道的图片，在项目中将调整为 （80, 80）的RGB图片；网络的第一层归一化层（Normalization Layer）采用了归一化操作，归一化作为输入卷积层之前的预处理操作，进行归一化操作有助于适配不同类型的网络结构，并且加速模型在GPU上的训练，在项目中省略了归一化层（把归一化操作放在数据预处理阶段，具体见下一章）；接下来的紧跟着五个卷积层（Convolutional Layer），前三个卷积层选择了5x5的kernel和2x2的strides，后两层卷积层选择了3x3的kernel并且没有strides，卷积核数量逐层增多（24→36→48→64→64）是有一定的解释的，卷积神经网络的特点是“局部视野”+“权值共享”，通过选取图像中部分区域（通过卷积核的大小决定）并选择多个卷积核（权值共享）来将提取到的局部特征应用到全局图片，卷积核的数量和层数越多可以提取到的特征越“通用”；卷积层之后增加了3个全连接层（Full Connected，简称FC），FC层用来对卷积层提取到的特征进行训练并最终输出转向控制信号。</p><div class="figure"><img src="/img/8.jpg" alt="1"><p class="caption">1</p></div><p>　　注意的是卷积层与FC层之间通过Flatten连接，实现了将卷积层输出的多维向量变成一维向量，用于输入FC层。模型构建好了以后，需要编译并选择训练优化算法，选择的是深度学习中常见的算法Adam optimizer<a href="#7">[7]</a>。同时，在除最后输出层外，其他各层使用RELU激活函数<a href="#5">[5]</a>，RELU输出所有负值为0，正值为本身，ReLU的优点在于它不会饱和，收敛快（即能快速找到代价函数的极值点），而且计算简单（函数形式很简单）；但是收敛快也使得ReLU比较脆弱，如果梯度的更新太快，还没有找到最佳值，就进入小于0的函数段，这会使得梯度变为0，无法更新梯度直接挂机了。所以，对于ReLU神经元，控制学习率（learning rate）十分重要。此外，它的输出也不是均值为零0的。</p><p>　　之所以要选择该模型为基准模型，是因为模型网络层不多且清晰，并且基于已被验证的假设（在实际道路测试中有良好效果，见论文<a href="#1">[1]</a>）。在经过10次epochs之后（经过简单测试，发现5次epochs训练不充分，20次epochs易过拟合，10次epochs训练合适，其它模型都将设置为10次以对比），生成器的bathch size为设置为128（数据预处理见下一章），基准模型的'training loss'（MSE）值为0.5361，‘validation loss’（MSE）值为0.5013，在测试集上MSE值为8.8617。从损失值看，基准模型学会了一定的驾驶策略，但存在过拟合（训练集和验证集损失值低，测试集高）。具体训练结果见图Figure 9。</p><div class="figure"><img src="/img/9.jpg" alt="1"><p class="caption">1</p></div><h1 id="iii.-方法">III. 方法</h1><h2 id="数据预处理">3.1 数据预处理</h2><p>　　在项目中的数据预处理分为两个步骤：单张图片处理测试、原始训练数据与测试数据生成。</p><h3 id="单张图片处理测试">3.1.1 单张图片处理测试</h3><p>　　按照处理数据由简到繁的逻辑，首先对单张图片做了处理测试：1.数据简化，包括裁剪和重设尺寸。裁剪掉天空部分（这一部分特征对模型训练帮助不大），并重设图片尺寸大小为80*80（减小所占内存空间，加快训练速度）；2.数据增加，使用了图片翻转和图片加噪声的方法。将图片水平翻转和加入随机噪声（在加噪声前使用了图片数据归一化技术），这样图片就增加了两倍。</p><p>　　处理前和处理后结果见图Figure 10。</p><div class="figure"><img src="/img/10.jpg" alt="1"><p class="caption">1</p></div><h3 id="原始训练数据与测试数据生成">3.1.2 原始训练数据与测试数据生成</h3><p>　　对整体的数据处理策略为：使用 python data generator（生成器）来进行数据的分批次从硬盘导入，同时使用数据增加的方法，对每批次进行数据增加处理（翻转和增加噪音）。</p><p>　　首先，需要将视频文件转换为图片保存进硬盘。原视频文件如果直接转换为图片读入内存中，会导致内存溢出（图片太大），所以需要对其进行简化(上一小节提到的数据简化方法)并保存进硬盘（数据持久化）统一处理，具体步骤如下：1.将所有视频文件转化为图片（RGB颜色通道，JPG格式）。2.在转换过程中，对每一张图片进行裁剪（将图片中天空部分剪掉），然后重设图片尺寸为宽、高为（80，80）的RGB颜色图片。3.将前9段视频转换为训练图片保存在硬盘中，将第10段视频转换为测试图片保存在硬盘中（经过裁剪和重设尺寸后可以将所有图片直接保存内存，在后面只对测试集使用此方式）。同时将对应的转向角度和图片路径保存为CSV文件。具体代码见'preprocess_data.py'文件中的'load_data()'函数。测试硬盘上的图片和csv文件结果如图Figure 11。</p><div class="figure"><img src="/img/11.jpg" alt="1"><p class="caption">1</p></div><p>　　然后，使用python data generator（生成器）从硬盘读入图片生成训练数据（测试数据因图片少可以直接读入内存）。对于大型图像的处理任务，图片不可能一次性加载入内存，在单机上又无法进行分布式处理，因此有必要采用生成器（python data generator）来进行数据的分批次导入。另外，深度学习只有在大量的训练集上才能体现出它的威力，过小的数据集会导致模型训练不充分。在本项目中，用于训练模型的数据集大小为24300，这些数据对于真实世界的路况而言太少了，需要增加数据（在生成器中使用前面的数据增加技术）。也就是说，虽然本项目经过数据简化后可以全部读入本机内存，但出于数据处理方式的一致性和学习目的考虑，对训练用的数据使用生成器来生成训练集和验证集（训练用样本80%划分为训练集，20%划分为验证集）。对于测试集则直接读入内存。在使用生成器分批次从硬盘导入数据时，要对数据进行增加处理（具体代码见'preprocess_data.py'文件中的'generator()'函数）：1.首先对读入图片进行归一化（Normalization），将图片数据大小范围缩小到 [0.1, 0.9] 区间。2.对图片进行水平翻转，增加一倍数据。3.对图片加入随机噪音，增加一倍数据（在这里先归一化，再加噪音，否则会产生没有图像图片）。4.经过处理后，总的数据就是原始数据的3倍（数据在开始处理和完成时都经过随机顺序打乱）。generator 生成的图片结果如图Figure 12。</p><div class="figure"><img src="/img/12.jpg" alt="1"><p class="caption">1</p></div><p>　　注意，本项目训练和验证都使用增加后的数据集（目的不是对比没有增加数据模型和增加数据模型的表现，在后面是要对比增加转向角度大的数据和没有增加转向角度大的数据模型之间的对比）。在前面“探索性可视化部分”提到，转向角度数据分布中转向角度大的数据较少，在具体执行过程中将随机增加这些数据（原样本大小为24300，增加后为40000），再使用生成器来分批次从硬盘导入数据生成训练集和验证集（总样本将达到120000），以观察模型表现是否提升。</p><h2 id="执行过程">3.2 执行过程</h2><h3 id="基准模型改进">3.2.1 基准模型改进</h3><p>　　在基准模型Nvidia model表现的基础上，首先对其进行改进。在原始模型中，使用的激活函数为RELU，在改进模型中，将使用ELU<a href="#5">[5]</a>进行替换，因为ReLU的输出值没有负值，所以输出的均值会大于0，当激活值的均值非0时，就会对下一层造成一个bias，如果激活值之间不会相互抵消（即均值非0），会导致下一层的激活单元有bias shift。如此叠加，单元越多时，bias shift就会越大。相比RELU，ELU可以取到负值，这让单元激活均值可以更接近0，ELU具有软饱和的特性，提升了对噪声的鲁棒性；在卷积层后增加BatchNormalization层和MaxPooling2D层。根据keras文档<a href="#8">[8]</a>，可知，BatchNormalization层在每个batch上将前一层的激活值重新规范化，即使得其输出数据的均值接近0，其标准差接近1，MaxPooling2D层为空域信号施加最大值池化。增加这两层的目的是避免过拟合和加快训练收敛速度；对每一层参数初始化方法改为'he_normal'，根据keras文档<a href="#8">[8]</a>，可知，He正态分布初始化方法，参数由0均值，标准差为sqrt(2 / fan_in) 的正态分布产生，其中fan_in为权重张量的输入；在全连接层后使用Dropout层，根据keras文档<a href="#8">[8]</a>，可知，Dropout将在训练过程中每次更新参数时按一定概率（rate）随机断开输入神经元，Dropout层用于防止过拟合。修改后，模型结构如图Figure 13：</p><div class="figure"><img src="/img/13.jpg" alt="1"><p class="caption">1</p></div><p>　　构建好改进模型后，采用基准模型的训练方法（优化算法为Adam optimizer），经过10次epochs（设置生成器的bathch size为128）之后，基准模型的'training loss'（MSE）值为1.4000，‘validation loss’（MSE）值为0.8484，在测试集上MSE值为4.4797。从损失值看，相比基准模型，训练集和验证集损失值增加，测试集损失值降低，说明模型的性能有所提升，模型人工转向偏差相较基准模型更小。具体训练结果见图Figure 14。</p><div class="figure"><img src="/img/14.jpg" alt="1"><p class="caption">1</p></div><h3 id="大转向角度数据添加">3.2.2 大转向角度数据添加</h3><p>　　在前面“探索性可视化部分”提到，转向角度数据分布中转向角度大的数据较少，为了避免因数据少而使得模型对比较大的转弯反应“迟钝”，将随机增加转向角度小于-5或大于5的样本，以对比增加前后增加后模型的表现是否有所提升。具体做法为：首先读取样本的CSV文件，然后提取转向角度小于-5或大于5的样本，最后随机增加转向幅度大的样本到样本集中。这样，总样本数从原来的24300增加到40000（增加了15700个转向角度大的样本）。划分训练集和验证集后（20%为验证集，80%为数据集），使用生成器（generator）批次导入训练图片和验证图片，期间使用数据增加技术没批次增加为原数据3倍。完成后，总的训练用图片数达到96000，验证用图片数达到24000，数据量还是比较充分。</p><p>　　完成大转向角度数据添加后，采用改进后的模型进行训练，优化算法为Adam optimizer，经过10次epochs（设置生成器的bathch size为128）之后，基准模型的'training loss'（MSE）值为1.8166，‘validation loss’（MSE）值为0.5717，在测试集上MSE值为3.2823。从损失值看，训练集和验证集的损失值相较没有添加大转向角度数据的模型变化不大，测试集损失值降低，说明增加后对模型是有帮助的，同时还需要结合时序图来分析对比预测转向和人工转向的差别。具体训练结果见图Figure 15。</p><div class="figure"><img src="/img/15.jpg" alt="1"><p class="caption">1</p></div><h2 id="完善">3.3 完善</h2><h3 id="构建">3.3.1 构建</h3><p>　　在完成Nvidia model模型（基准、改进、完善数据集）之后，将进一步使用迁移学习来完善整个项目。这里将选用VGG16 + Nvidia 模型来作为Nvidia model的对比模型。</p><p>　　剑桥大学和Google DeepMind的研究人员在2014年论文<a href="#6">[6]</a>中提出的一种用于大规模图像识别的深度卷积神经网络，大体思想是用较小的卷积核（3x3）和较深的卷积层（16–19层）对图像通用特征进行提取，VGG16的网络结构图见 Figure 16，从图中可以看出，黑色的卷积层加上红色的池化层位一个block，所以共有5个block作为特征提取，最后加上3个FC层。在实践中训练VGG16的数据集主要来自于ImageNet。VGG16可以在ImageNet这种涵盖多种类物体图像的大规模数据集上进行训练，对ImageNet中包括的景物有较强的识别能力，我们可以借鉴迁移学习的思想，利用VGG16来构建对比模型，设计的基本思想是使用VGG16来提取图像特征，然后加上FC全连接层来进行回归预测。</p><div class="figure"><img src="/img/16.jpg" alt="1"><p class="caption">1</p></div><p>　　正如前面“算法和技术”章节提到将选用 fine-tuned策略， fine-tuned有两个使用方法：一是新的数据集比较大，而且与pre-train model的训练数据集比较接近，则直接使用pre-train model的参数权重是比较合理的，因为此时网络结构和设置不会在新的数据集上过拟合，而且采用原有网络的参数权重可以加速训练收敛；二是新的数据集比较小，而且与pre-train model的训练数据集差距比较大，此时应仅用顶部几层的结构和权重，最后几层提取的特征可能过于局限在原数据集。这两种方法在项目中都将尝试。另外，VGG16初始模型来源于链接<a href="#9">[9]</a>，训练好的模型权重参数保存为.h5文件中，分为notop和withtop两种，其中notop不包含原VGG结构的3个FC层，可以广泛应用在特征提取中，keras使用的VGG16 notop的权重来源于链接<a href="#10">[10]</a>。最终VGG16 + Nvidia模型如图 Figure 17。</p><div class="figure"><img src="/img/17.jpg" alt="1"><p class="caption">1</p></div><p>　　模型说明：在模型建构中使用了GlobalAveragePooling2D层代替了Flatten层，因为（80，80，3）的输入图片在block5层输出后维度为（2，2，512），这里为空域信号施加全局平均值池化，可以输出一维向量，在实际训练中发现效果更好。另外参考基准模型，将中间4层FC层简化为3层，加快训练速度，同时在除最后输出层外其他FC层后加上Dropout层防止过拟合。</p><h3 id="训练">3.3.2 训练</h3><p>　　VGG16 + Nvidia 模型训练按照前一小节提到的 fine-tuned策略分为两种：一是notop + noblocks。即直接使用预训练好的权重，之训练FC层权重参数；二是notop + top2 bolocks。即固定前3个block的参数权重，只训练微调4，5个block的参数权重已经FC层权重参数。然后再加上转向角度大的数据对表现较好的方法模型进行训练。所以，总共是3种方法训练模型。结果如下：</p><p>　　1.notop + noblocks，采用和基准模型相同的训练方法和数据集（优化算法为Adam optimizer，10次epochs，原生成器生成的训练集验证集），将生成器的batch size设置为64。训练结果发现模型的训练集和验证集的损失值都没有收敛，说明tesla的数据集和VGG16 pre-train model的训练数据集相差较大，所以这种方法不可取。</p><p>　　2.notop + top2 bolocks, 采用和基准模型相同的训练方法和数据集（优化算法为Adam optimizer，10次epochs, 生成器生成的训练集验证集），将生成器的batch size设置为64。模型的'training loss'（MSE）值为5.3162，‘validation loss’（MSE）值为 4.5624，在测试集上MSE值为2.7826。具体训练结果见图Figure18，虽然训练集和验证集损失值比较高，但在测试集上表现比Nvidia模型更好，说明模型学会了驾驶转向的一般策略。</p><div class="figure"><img src="/img/18.jpg" alt="1"><p class="caption">1</p></div><p>　　3.notop + top2 bolocks + 大转向角度数据增加, 采用和“大转向角度数据添加”小节相同的训练方法和数据集（优化算法为Adam optimizer，10次epochs, 增加转向角度数据后的生成器生成的训练集验证集），将生成器的batch size设置为128。模型的'training loss'（MSE）值为4.2552，‘validation loss’（MSE）值为 2.9988，在测试集上MSE值为3.5445。增加转向幅度大的sample后，模型在验证集上有所提升，但测试集损失值反而增加了。在这里并没有看出增加后对模型有帮助，但还需要结合时序图来分析对比预测转向和人工转向的差别。具体训练结果见图Figure 19。</p><div class="figure"><img src="/img/19.jpg" alt="1"><p class="caption">1</p></div><h1 id="iv.-结果">IV. 结果</h1><h2 id="模型的评价与验证">4.1 模型的评价与验证</h2><p>　　在对上面基模型、基模型改进、基模型改进+大转向数据、VGG16+Nvidia（notop + top2 bolocks）和VGG16+Nviida（notop + top2 bolocks + 大转向角度数据增加）经过多次训练后发现，VGG16 + Nvidia model的训练结果曲线明显比Nvidia model的更平滑；另外，每次因对初始权重的随机设置，训练集、验证集和测试集结果会有不同（但一般总体MSE值的差别不超过5），大体来说VGG16 + Nvidia model表现是普遍好于Nvidia model，增加大转向角度后模型表现是普遍好于不增加训练的模型。但这也从侧面说明一个问题，仅凭MSE作为模型表现判断标准是不完善的，因为一个智能的好的模型应该是总体预测走势接近于人工的，而有时一个模型MSE值小可能是因为对大的转向不敏感，或有时普遍准确的预测掩盖了某些时刻比较严重的错误。所以，在模型评价和最优模型的选择上，还要进行各个模型转向角度时间序列图的比较。如图Figure 20。</p><div class="figure"><img src="/img/20.jpg" alt="1"><p class="caption">1</p></div><p>　　从上面各模型的时间序列图可以看出，后两个VGG16+Nvidia model 明显比前三个Nvidia model输出的角度更平滑和贴合原始方向角度，同时从前面各模型测试集的MSE值也可以看出后两个模型更出色。所以应该选用VGG16+Nvidia model，虽然'VGG16 + Nvidia model：notop + top2 bolocks'比'VGG16 + Nvidia model：notop + top2 bolocks + 转向角度数据增加'输出的'test loss'要小，但从图中可以看出，后者明显比前者的图形走势更接近于原始的数据走势，所以最终的模型应该为最后一个模型'VGG16 + Nvidia model：notop + top2 bolocks + 转向角度数据增加'。</p><h2 id="合理性分析">4.2 合理性分析</h2><p>　　综上，将基准模型和最佳模型对比可以发现，基准模型在测试集的MSE值（8.8617）和转向角度时间序列图（预测值和真实值对比）上都比最终模型MSE值（3.5445）和时间序列图的表现要差。特别是在时间序列图上可以看出，基准模型在预测上是相当不准确的，而最终模型在预测上已经比较接近人工驾驶。所以，在项目开始时所要讨论的问题（比较准确的预测转向角度）得到了解决。</p><h1 id="v.-项目结论">V. 项目结论</h1><h2 id="结果可视化">5.1 结果可视化</h2><p>　　最后，将使用最终模型在第10段视频上生成转向角度预测视频，如图Figure 21。这实际上就是将时间序列图（人工和模型预测的角度对比）和驾驶视频结合起来，前面已经讨论了时间序列图的相关结果（注意：图中红线表示预测值，蓝线表示真实值，这和上面时间序列图有所不同），这里不再赘述。 <img src="/img/21.jpg" alt="1"></p><h2 id="对项目的思考">5.2 对项目的思考</h2><p>　　本项目大致可以分为四个阶段：首先、进行了简单的数据探索（视频和CSV文件）；二、数据预处理。包括所有视频转换为图片保存到硬盘，使用生成器（generator）从硬盘读取图片生成训练集和验证集（测试集保存到内存），期间使用数据简化（裁剪、缩小图片尺寸）和数据增加（水平翻转、图片增加噪音）技术；三、利用Keras训练模型并导出模型参数。完成了基模型（Nvidia model）、基模型改进（NVIDIA refined model）、基模型改进+大转向数据、VGG16+Nvidia（notop + top2 bolocks）和VGG16+Nviida（notop + top2 bolocks + 大转向角度数据增加）5个模型的训练。然后讨论了各模型的MSE值和时间序列图表现。四、选择最佳模型并生成最终视频。选择VGG16+Nviida（notop + top2 bolocks + 大转向角度数据增加）模型为最终模型，并使用最终模型在第10段视频上生成了结果视频。</p><p>　　另外，在项目中完成了两个选做模型。一个是VAE + GAN model生成训练用图片，另一个是CNN+RNN seq2seq model来预测转向角度。这两个选做项目难度较大而且完成度还有待提高，每一个设计的技术和方法都可以单独用一篇文章进行总结，所以在这里并没有对它们进行讨论，留待后续探讨。</p><p>　　项目中模型架构，超参数的调试都能体会到难度和兴趣点（为了使整个项目报告简洁，项目中很多参数调试过程并没有呈现：如不同epochs训练下模型表现、个别网络层添加删除后效果、不同学习率调试的效果，不同优化算法的尝试等。呈现的都是最终调试好的结果）。选做项目是整个项目最难的地方，但收获也比较多。总体来说，最终模型和结果达到预期目标，其中的涉及到的技术和算法在类似的场景中也有一定的通用性。</p><h2 id="需要作出的改进">5.3 需要作出的改进</h2><p>　　需要改进的地方有：</p><p>　　 1.在数据预处理阶段，尝试更多的图片处理技术（如平移、加阴影等）。</p><p>　　 2.在迁移学习中可以使用其它更好的原始模型，如ResNet 50。</p><p>　 　 3.对选做项目中涉及的模型还可以进一步优化（使用更完善的LSTM神经网络）。</p><p>　　 4.使用更多的训练集（如百度阿波罗平台的数据）对模型进行训练。</p><h1 id="vi.-参考文献">VI. 参考文献</h1><p>[ 1 ]：<span id="1">M. Bojarski, D. Del Testa, D. Dworakowski, B. Firner,B. Flepp, P. Goyal, L. D. Jackel, M. Monfort, U. Muller, J. Zhang, et al. End to end learning for self-driving cars. arXiv preprint arXiv:1604.07316, 2016.</span></p><p>[ 2 ]：<span id="2">E. Santana and G. Hotz, “Learning a driving simulator,” arXiv preprint arXiv:1608.01230, 2016.</span></p><p>[ 3 ]：<span id="3">Udacity. An open source self-driving car, 2017：https://medium.com/udacity/teaching-a-machine-to-steer-a-car-d73217f2492c</span></p><p>[ 4 ]：<span id="4">D. A. Pomerleau, “Alvinn, an autonomous land vehicle in a neural network,” Carnegie Mellon University, Computer Science Department, Tech. Rep., 1989.</span></p><p>[ 5 ]：<span id="5">A. Karpathy, “Cs231n convolutional neural networks for visual recognition,” http://cs231n.github.io/convolutional-networks/, 2016.</span></p><p>[ 6 ]：<span id="6">K Simonyan, A Zisserman, “Very Deep Convolutional Networks for Large-Scale Image Recognition,” arXiv preprint arXiv:1409.1556, 2015.</span></p><p>[ 7 ]：<span id="7">Diederik P. Kingma, Jimmy Ba, “Adam: A Method for Stochastic Optimization,” arXiv:1412.6980, 2014.</span></p><p>[ 8 ]：<span id="8">Keras中文文档：http://keras-cn.readthedocs.io/en/latest/</span></p><p>[ 9 ]：<span id="9">VGG16初始模型的.py文件：https://github.com/fchollet/deep-learning-mdels/blob/master/vgg16.py</span></p><p>[10]：<span id="10">WEIGHTS PATH NO TOP：https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5</span></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/img/tesla.jpg&quot; alt=&quot;tesla&quot;&gt; 　　&lt;strong&gt;前段时间完成了MIT 6.S094：DeepTesla的小项目（用深度学习预测特斯拉转向角度），做了个总结，分享给大家。&lt;/strong&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="无人驾驶" scheme="http://yoursite.com/tags/%E6%97%A0%E4%BA%BA%E9%A9%BE%E9%A9%B6/"/>
    
  </entry>
  
  <entry>
    <title>机器学习 学习卡片（A）</title>
    <link href="http://yoursite.com/2017/11/11/A/"/>
    <id>http://yoursite.com/2017/11/11/A/</id>
    <published>2017-11-10T16:00:00.000Z</published>
    <updated>2017-12-12T09:50:14.915Z</updated>
    
    <content type="html"><![CDATA[<p>​<img src="/img/card/ChrisAlbon.jpeg" alt="ChrisAlbon"></p><p>​　　<strong>最近在twitter上发现数据科学家Chris Albon（他有近十年的统计学习、人工智能和软件工程方面的经验），他绘制了100多张（还在不断更新）机器学习概念的卡片命名为MachineLearningFlashCards，用生动的线条和有趣的图案，将晦涩难懂的机器学习知识点，变得平易近人，一看就懂，这里将全部翻译出来放在博客上，给大家参考。</strong> <strong>说明：每次按字母顺序更新，不超过5张。第一期更新关于A字母的五个概念：</strong> <a id="more"></a></p><h1 id="机器学习-学习卡片a">机器学习 学习卡片（A）</h1><h2 id="准确率accuracy">1.准确率(Accuracy)</h2><div class="figure"><img src="/img/card/Accuracy.jpg" alt="Accuracy"><p class="caption">Accuracy</p></div><p>准确率：分类问题中常用的度量标准。当类别中数量分布不平衡时这种度量方法不能起作用，需要使用F1分数更为合适。</p><h2 id="自适应提升算法adaboost">2.自适应提升算法(AdaBoost)</h2><div class="figure"><img src="/img/card/Adaboost.jpg" alt="Accuracy"><p class="caption">Accuracy</p></div><p>自适应提升算法：</p><ul><li><p>1、为每一个观测值Xi赋一个初始的权重值，Wi = 1/n，n是观测值总数。</p></li><li><p>2、训练一个“弱”模型。（通常是决策树）</p></li><li><p>3、对于每一个观测值：</p></li></ul><p>a)如果预测值错误，Wi增加</p><p>b)如果预测值正确，Wi减少</p><ul><li><p>4、训练一个新的弱模型，其中，有更高权重的观测值获得更高优先级。</p></li><li><p>5、重复第3、4步，直到观测值都能被完美预测出来或者预设数量的树都被训练完了。</p></li></ul><h2 id="调整r平方adjusted-r-squared">3.调整R平方(Adjusted R-Squared)</h2><div class="figure"><img src="/img/card/Adjusted%20R-Squared.jpg" alt="Accuracy"><p class="caption">Accuracy</p></div><p>调整R平方：</p><p>直观上：一旦所有正确的特征都已经加上，额外的特征应该被惩罚。因此调整R平方将为每个新加入的变量特征付出代价。</p><h2 id="赤池信息量准则akaike-information-criterion">4.赤池信息量准则((Akaike information criterion)</h2><div class="figure"><img src="/img/card/AIC.jpg" alt="Accuracy"><p class="caption">Accuracy</p></div><p>AIC(Akaike information criterion)：是衡量统计模型拟合优良性的一种标准，在特征选择时用于比较哪个模型更好。AIC越小越好。</p><h2 id="避免过拟合avoid-overfitting">5.避免过拟合(Avoid Overfitting)</h2><div class="figure"><img src="/img/card/Avoid%20Overfitting.jpg" alt="Accuracy"><p class="caption">Accuracy</p></div><p>避免过拟合：简单模型；交叉验证评估；正则化；获取更多数据；集成学习。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;​&lt;img src=&quot;/img/card/ChrisAlbon.jpeg&quot; alt=&quot;ChrisAlbon&quot;&gt;&lt;/p&gt;
&lt;p&gt;​　　&lt;strong&gt;最近在twitter上发现数据科学家Chris Albon（他有近十年的统计学习、人工智能和软件工程方面的经验），他绘制了100多张（还在不断更新）机器学习概念的卡片命名为MachineLearningFlashCards，用生动的线条和有趣的图案，将晦涩难懂的机器学习知识点，变得平易近人，一看就懂，这里将全部翻译出来放在博客上，给大家参考。&lt;/strong&gt; &lt;strong&gt;说明：每次按字母顺序更新，不超过5张。第一期更新关于A字母的五个概念：&lt;/strong&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="机器学习卡片" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8D%A1%E7%89%87/"/>
    
  </entry>
  
</feed>
